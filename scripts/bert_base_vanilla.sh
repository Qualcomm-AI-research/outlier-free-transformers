#!/bin/bash
accelerate launch --config_file accelerate_configs/1gpu_fp16.yaml run_mlm.py \
--config_path model_configs/bert-15m.yaml \
--run_name bert-vanilla-15m \
--with_tracking \
--report_to wandb \
--project_name quantizable_transformers \
--extra_tb_stats \
--seed 1000 \
--dataset_setup bookcorpus_and_wiki \
--preprocessing_num_workers 6 \
--data_cache_dir ~/.hf_data \
--model_cache_dir ~/.hf_cache \
--model_type bert \
--tokenizer_name bert-base-uncased \
--mlm_probability 0.15 \
--lr_scheduler_type cosine \
--num_warmup_steps 10000 \
--max_grad_norm 1.0 \
--weight_decay 0.01 \
--config_name bert-base-uncased \
--checkpointing_steps 50000 \
--gradient_accumulation_steps 8 \
--attn_softmax vanilla \
--output_dir output \
--train_percentage 1 \
--validation_percentage 1